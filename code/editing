import os
import json
import pandas as pd
import numpy as np
import re
import requests
from bs4 import BeautifulSoup
from scipy import stats
from io import StringIO
from datetime import datetime
import glob

# Define constants
OUTPUT_DIR = r"C:\Users\Student\Desktop\NBA_Algorithm\code\games"

def load_betting_lines_from_json(team_name=None, player_name=None):
    """
    Load betting lines from JSON files in the games directory.
    Can filter by team name and/or player name.
    Returns a dictionary of players and their betting lines.
    """
    if not os.path.exists(OUTPUT_DIR):
        print(f"Directory not found: {OUTPUT_DIR}")
        return {}
    
    # Find all JSON files in the directory
    json_files = glob.glob(os.path.join(OUTPUT_DIR, "*_props.json"))
    if not json_files:
        print(f"No prop betting files found in {OUTPUT_DIR}")
        return {}
    
    # Get the most recent JSON file or filter by team
    if team_name:
        # Convert team name to format likely in filename
        team_name_formatted = team_name.replace(' ', '_')
        matching_files = [f for f in json_files if team_name_formatted in f]
        if not matching_files:
            print(f"No files found for team: {team_name}")
            # Fall back to most recent file
            matching_files = sorted(json_files, key=os.path.getmtime, reverse=True)
    else:
        # Just get the most recent file
        matching_files = sorted(json_files, key=os.path.getmtime, reverse=True)
    
    if not matching_files:
        print("No suitable JSON files found")
        return {}
    
    # Use the most recent matching file
    latest_file = matching_files[0]
    print(f"Loading betting lines from: {os.path.basename(latest_file)}")
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Extract game information from metadata
        game_info = data.get('metadata', {}).get('game', {})
        home_team = game_info.get('home_team', 'Unknown')
        away_team = game_info.get('away_team', 'Unknown')
        game_date = game_info.get('formatted_date', 'Unknown Date')
        
        print(f"Game: {away_team} at {home_team} on {game_date}")
        
        # Process player props
        players_props = {}
        player_list = data.get('props', {}).get('players', [])
        
        for player_data in player_list:
            player_full_name = player_data.get('name', '')
            player_team = player_data.get('team', '')
            
            # Filter by player name if specified
            if player_name and player_name.lower() not in player_full_name.lower():
                continue
            
            # Initialize player props dictionary
            players_props[player_full_name] = {
                'team': player_team,
                'props': {}
            }
            
            # Process each market for the player
            for market in player_data.get('markets', []):
                stat = market.get('stat', '')
                line = market.get('line')
                
                # Skip if no line available
                if line is None:
                    continue
                
                # Map stat names to match the playoff predictor's format
                stat_mapping = {
                    'points': 'PTS',
                    'assists': 'AST',
                    'rebounds': 'TRB',
                    'points_rebounds_assists': 'PRA'
                }
                
                stat_key = stat_mapping.get(stat, stat.upper())
                
                players_props[player_full_name]['props'][stat_key] = {
                    'line': line,
                    'over_odds': market.get('over', {}).get('odds'),
                    'over_prob': market.get('over', {}).get('implied_probability'),
                    'under_odds': market.get('under', {}).get('odds'),
                    'under_prob': market.get('under', {}).get('implied_probability')
                }
        
        return {
            'game_info': {
                'home_team': home_team,
                'away_team': away_team,
                'date': game_date
            },
            'players': players_props
        }
        
    except Exception as e:
        print(f"Error loading JSON file: {e}")
        return {}

def create_player_playoff_url(first_name, last_name, season=None):
    """
    Create the correct Basketball Reference URL for a player's playoff data.
    Format: first letter of last name/first 5 letters of last name + first 2 letters of first name
    Example: Stephen Curry -> c/curryst01/gamelog-playoffs/
    """
    # Format names correctly
    first_name = first_name.strip().lower()
    last_name = last_name.strip().lower()
   
    # Create the initial part of the player ID
    first_letter = last_name[0]
    last_name_part = last_name[:5]
    first_name_part = first_name[:2]
   
    # Construct base URL pattern
    player_id = f"{last_name_part}{first_name_part}01"
   
    # If season is specified, add it to the URL
    if season:
        base_url = f"https://www.basketball-reference.com/players/{first_letter}/{player_id}/gamelog-playoffs/{season}"
    else:
        base_url = f"https://www.basketball-reference.com/players/{first_letter}/{player_id}/gamelog-playoffs/#player_game_log_post"
   
    # Check if this URL exists
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(base_url, headers=headers)
        if response.status_code == 200:
            return base_url, player_id
       
        # If not found, we should search more systematically
        print(f"Player page not found. Attempted URL: {base_url}")
        print("The player ID might have a different sequence number or format.")
        return None, None
    except Exception as e:
        print(f"Error accessing URL: {e}")
        return None, None

def get_playoff_games(player_url):
    """Fetches and returns all available playoff games of a player."""
    try:
        # Get the HTML content
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(player_url, headers=headers)
       
        # Check if response is successful
        if response.status_code != 200:
            print(f"Failed to access {player_url}, status code: {response.status_code}")
            return None
           
        soup = BeautifulSoup(response.content, 'html.parser')
       
        # Find all playoff tables
        playoff_tables = []
       
        # Check for tables with different possible ID patterns
        table_patterns = [
            re.compile(r'pgl_basic_playoffs'),  # Standard pattern
            re.compile(r'playoffs_.*'),         # Alternative pattern
            re.compile(r'post_.*')              # Another possible pattern
        ]
       
        for pattern in table_patterns:
            tables = soup.find_all('table', id=pattern)
            if tables:
                playoff_tables.extend(tables)
       
        # If no tables found with IDs, try looking for tables with specific class names
        if not playoff_tables:
            # Look for tables that might contain playoff data
            for table in soup.find_all('table'):
                # Look for headers or captions that indicate playoff data
                caption = table.find('caption')
                if caption and ('playoff' in caption.text.lower() or 'post' in caption.text.lower()):
                    playoff_tables.append(table)
               
                # Check for playoff indicators in table classes or attributes
                if table.has_attr('class') and any('playoff' in c.lower() for c in table['class']):
                    playoff_tables.append(table)
       
        # Last resort: if still no tables found, try to find any div containing playoff data
        if not playoff_tables:
            playoff_divs = soup.find_all('div', id=re.compile(r'div_playoffs'))
            for div in playoff_divs:
                tables = div.find_all('table')
                playoff_tables.extend(tables)
       
        if not playoff_tables:
            print(f"No playoff tables found at {player_url}")
            # Try to determine if this is due to no playoff appearances or website structure issue
            if "Playoffs" not in soup.text and "playoff" not in soup.text.lower():
                print("Player may not have playoff appearances.")
            else:
                print("Tables exist but could not be properly accessed. Website structure may have changed.")
            return None
       
        # Process all tables
        all_playoff_data = []
        for table in playoff_tables:
            # Convert HTML table to DataFrame - use StringIO to avoid FutureWarning
            html = str(table)
            try:
                dfs = pd.read_html(StringIO(html))
                if not dfs:
                    continue
                df = dfs[0].copy()  # Create a copy to avoid SettingWithCopyWarning
               
                # Clean the DataFrame - remove header rows and summary rows
                if 'Rk' in df.columns:
                    # Filter out header repetitions and summary rows (TOT)
                    df = df[~df['Rk'].isin(['Rk', 'TOT'])].copy()
                    # Convert 'Rk' to numeric to further filter out non-numeric values
                    df['Rk'] = pd.to_numeric(df['Rk'], errors='coerce')
                    df = df[df['Rk'].notna()].copy()
               
                # Extract season information
                season = "Unknown"
                if table.get('id'):
                    season_match = re.search(r'playoffs_(\d+)', table.get('id', ''))
                    if season_match:
                        season = season_match.group(1)
                else:
                    # Try to extract season from nearby elements
                    for element in table.previous_siblings:
                        if hasattr(element, 'text') and re.search(r'20\d{2}-\d{2}', element.text):
                            season_match = re.search(r'20\d{2}-\d{2}', element.text)
                            if season_match:
                                season = season_match.group(0)
                                break
               
                # Add series information based on patterns in data (use .loc to avoid SettingWithCopyWarning)
                if 'Opp' in df.columns:
                    df.loc[:, 'Series'] = df['Opp'].apply(lambda x: x if pd.notna(x) else '')
                else:
                    df.loc[:, 'Series'] = ''
                   
                # Add Game_In_Series - check if 'G' or 'Gm' or 'Game' column exists
                game_col = None
                for possible_col in ['Gm', 'G', 'Game', '#']:
                    if possible_col in df.columns:
                        game_col = possible_col
                        break
                       
                if game_col:
                    df.loc[:, 'Game_In_Series'] = df[game_col].apply(
                        lambda x: int(x) if pd.notna(x) and str(x).isdigit() else 0)
                else:
                    df.loc[:, 'Game_In_Series'] = 0
               
                # Ensure we have a 'Gm' column to avoid KeyError later
                if 'Gm' not in df.columns:
                    if game_col:
                        df.loc[:, 'Gm'] = df[game_col]
                    else:
                        df.loc[:, 'Gm'] = df['Game_In_Series']
               
                # Add the season information
                df.loc[:, 'Season'] = season
               
                # Make sure required columns exist
                required_cols = ['PTS', 'AST', 'TRB', 'MP', 'Date', 'Opp', 'Result']
                for col in required_cols:
                    if col not in df.columns:
                        if col == 'PTS' and 'PT' in df.columns:  # Some tables use PT instead of PTS
                            df.loc[:, 'PTS'] = df['PT']
                        elif col == 'TRB' and 'REB' in df.columns:  # Some tables use REB instead of TRB
                            df.loc[:, 'TRB'] = df['REB']
                        else:
                            df.loc[:, col] = np.nan
               
                all_playoff_data.append(df)
               
            except Exception as e:
                print(f"Error processing table: {e}")
                continue
       
        # Combine all tables
        if all_playoff_data:
            combined_df = pd.concat(all_playoff_data, ignore_index=True)
           
            # Additional filtering for summary rows that might have slipped through
            if 'Rk' in combined_df.columns:
                # Convert Rk to numeric and filter out non-numeric values
                combined_df['Rk'] = pd.to_numeric(combined_df['Rk'], errors='coerce')
                combined_df = combined_df[combined_df['Rk'].notna()].copy()
           
            # Filter out rows that might contain "Totals" in any column
            for col in combined_df.columns:
                if combined_df[col].dtype == 'object':
                    combined_df = combined_df[~combined_df[col].astype(str).str.contains('Total', case=False, na=False)].copy()
           
            # Convert date to datetime
            combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')
           
            # Ensure numeric conversion for key stats
            numeric_cols = ['PTS', 'AST', 'TRB', 'MP', 'FG', 'FGA', '3P', '3PA', '2P', '2PA', 'FT', 'FTA',
                           'ORB', 'DRB', 'STL', 'BLK', 'TOV', 'PF', '+/-']
            for col in numeric_cols:
                if col in combined_df.columns:
                    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')
           
            # Add PRA (Points + Rebounds + Assists)
            if all(col in combined_df.columns for col in ['PTS', 'AST', 'TRB']):
                combined_df.loc[:, 'PRA'] = combined_df['PTS'] + combined_df['AST'] + combined_df['TRB']
           
            # Sort by date descending (most recent first)
            combined_df = combined_df.sort_values(by='Date', ascending=False)
           
            return combined_df
        else:
            print(f"No playoff data found for player at {player_url}")
            return None
    except Exception as e:
        print(f"Error fetching playoff data from {player_url}: {e}")
        return None

def extract_series_info(df):
    """Extract playoff series information from the dataframe."""
    if df is None or df.empty:
        return None
   
    # Make a copy to avoid modifying the original
    series_df = df.copy()
   
    # Filter out summary rows which can inflate statistics
    if 'Rk' in series_df.columns:
        # Convert to numeric and filter out non-numeric values (like 'Rk', 'TOT')
        series_df['Rk'] = pd.to_numeric(series_df['Rk'], errors='coerce')
        series_df = series_df[series_df['Rk'].notna()].copy()
   
    # Extract series information - handling potential missing columns
    def create_series_info(row):
        season = row['Season'] if 'Season' in row and pd.notna(row['Season']) else 'Unknown'
        opponent = row['Opp'] if 'Opp' in row and pd.notna(row['Opp']) else 'Unknown'
        game = row['Gm'] if 'Gm' in row and pd.notna(row['Gm']) else (
               row['Game_In_Series'] if 'Game_In_Series' in row and pd.notna(row['Game_In_Series']) else 'Unknown')
       
        return f"{season} - {opponent} - Game {game}"
   
    # Apply the function safely
    series_df.loc[:, 'Series_Info'] = series_df.apply(create_series_info, axis=1)
   
    # Group by opponent and season to identify different series
    def create_series_id(row):
        season = row['Season'] if 'Season' in row and pd.notna(row['Season']) else 'Unknown'
        opponent = row['Opp'] if 'Opp' in row and pd.notna(row['Opp']) else 'Unknown'
        return f"{season}_{opponent}"
   
    series_df.loc[:, 'Series_ID'] = series_df.apply(create_series_id, axis=1)
   
    return series_df

def get_games_vs_team(df, team_abbr):
    """Filter games against a specific team."""
    if df is None or df.empty:
        return None
   
    # Filter games against the team
    team_games = df[df['Opp'].str.contains(team_abbr, na=False)].copy()
   
    return team_games

def calculate_playoff_stats(df, team_abbr=None):
    """Calculate playoff statistics for a player."""
    if df is None or df.empty:
        print("No playoff data available.")
        return None, None, None
   
    # Make a clean copy of the dataframe
    df_clean = df.copy()
   
    # Filter out summary rows to avoid inflating averages
    if 'Rk' in df_clean.columns:
        # Convert Rk to numeric and filter out non-numeric values (like 'Rk', 'TOT')
        df_clean['Rk'] = pd.to_numeric(df_clean['Rk'], errors='coerce')
        df_clean = df_clean[df_clean['Rk'].notna()].copy()
   
    # Additional filtering for 'Total' rows that might inflate stats
    for col in df_clean.columns:
        if df_clean[col].dtype == 'object':
            df_clean = df_clean[~df_clean[col].astype(str).str.contains('Total', case=False, na=False)].copy()
   
    # Add series context information
    series_df = extract_series_info(df_clean)
   
    # Make sure PTS, AST, TRB are numeric
    for col in ['PTS', 'AST', 'TRB']:
        if col in series_df.columns:
            series_df[col] = pd.to_numeric(series_df[col], errors='coerce')
   
    # Calculate overall playoff averages - only include rows with valid points data
    valid_data = series_df[series_df['PTS'].notna()].copy()
   
    playoff_avg = {
        'PTS': valid_data['PTS'].mean() if not valid_data.empty else np.nan,
        'AST': valid_data['AST'].mean() if not valid_data.empty else np.nan,
        'TRB': valid_data['TRB'].mean() if not valid_data.empty else np.nan,
        'PRA': valid_data['PRA'].mean() if 'PRA' in valid_data.columns and not valid_data.empty else np.nan
    }
   
    # Calculate standard deviations
    playoff_std = {
        'PTS': valid_data['PTS'].std() if not valid_data.empty else np.nan,
        'AST': valid_data['AST'].std() if not valid_data.empty else np.nan,
        'TRB': valid_data['TRB'].std() if not valid_data.empty else np.nan,
        'PRA': valid_data['PRA'].std() if 'PRA' in valid_data.columns and not valid_data.empty else np.nan
    }
   
    # Get last 10 playoff games - make sure they're valid games with stats
    last_10_games = valid_data.head(10)
   
    # Calculate last 10 games averages
    last_10_avg = {
        'PTS': last_10_games['PTS'].mean() if not last_10_games.empty else np.nan,
        'AST': last_10_games['AST'].mean() if not last_10_games.empty else np.nan,
        'TRB': last_10_games['TRB'].mean() if not last_10_games.empty else np.nan,
        'PRA': last_10_games['PRA'].mean() if 'PRA' in last_10_games.columns and not last_10_games.empty else np.nan
    }
   
    # Last 10 games standard deviation
    last_10_std = {
        'PTS': last_10_games['PTS'].std() if not last_10_games.empty else np.nan,
        'AST': last_10_games['AST'].std() if not last_10_games.empty else np.nan,
        'TRB': last_10_games['TRB'].std() if not last_10_games.empty else np.nan,
        'PRA': last_10_games['PRA'].std() if 'PRA' in last_10_games.columns and not last_10_games.empty else np.nan
    }
   
    # If team is specified, calculate stats against that team
    if team_abbr:
        team_games = get_games_vs_team(valid_data, team_abbr)
       
        if team_games is not None and not team_games.empty:
            team_avg = {
                'PTS': team_games['PTS'].mean(),
                'AST': team_games['AST'].mean(),
                'TRB': team_games['TRB'].mean(),
                'PRA': team_games['PRA'].mean() if 'PRA' in team_games.columns else np.nan
            }
           
            team_std = {
                'PTS': team_games['PTS'].std(),
                'AST': team_games['AST'].std(),
                'TRB': team_games['TRB'].std(),
                'PRA': team_games['PRA'].std() if 'PRA' in team_games.columns else np.nan
            }
        else:
            team_avg = {stat: float('nan') for stat in ['PTS', 'AST', 'TRB', 'PRA']}
            team_std = {stat: float('nan') for stat in ['PTS', 'AST', 'TRB', 'PRA']}
    else:
        team_avg = {stat: float('nan') for stat in ['PTS', 'AST', 'TRB', 'PRA']}
        team_std = {stat: float('nan') for stat in ['PTS', 'AST', 'TRB', 'PRA']}
   
    # Create DataFrames for summary display
    stats_df = pd.DataFrame({
        'Stat': ['PTS', 'AST', 'TRB', 'PRA'],
        'Playoff Career Avg': [playoff_avg['PTS'], playoff_avg['AST'], playoff_avg['TRB'], playoff_avg['PRA']],
        'Last 10 Playoff Games Avg': [last_10_avg['PTS'], last_10_avg['AST'], last_10_avg['TRB'], last_10_avg['PRA']],
        f'Vs {team_abbr} Playoff Avg': [team_avg['PTS'], team_avg['AST'], team_avg['TRB'], team_avg['PRA']]
    })
   
    std_df = pd.DataFrame({
        'Stat': ['PTS', 'AST', 'TRB', 'PRA'],
        'Playoff Career StdDev': [playoff_std['PTS'], playoff_std['AST'], playoff_std['TRB'], playoff_std['PRA']],
        'Last 10 Playoff Games StdDev': [last_10_std['PTS'], last_10_std['AST'], last_10_std['TRB'], last_10_std['PRA']],
        f'Vs {team_abbr} Playoff StdDev': [team_std['PTS'], team_std['AST'], team_std['TRB'], team_std['PRA']]
    })
   
    # Round for cleaner display
    for col in stats_df.columns[1:]:
        stats_df[col] = stats_df[col].round(1)
    for col in std_df.columns[1:]:
        std_df[col] = std_df[col].round(1)
   
    return stats_df, std_df, valid_data

def calculate_betting_probability(stat_values, line_value, mean=None, std=None):
    """
    Calculate the probability of a player exceeding a betting line.
    Uses a combination of normal distribution and historical frequency.
    """
    # Remove NaN values
    stat_values = stat_values.dropna()
    if len(stat_values) < 3:
        return None, None, None, None
   
    # Calculate mean and standard deviation if not provided
    if mean is None:
        mean = stat_values.mean()
    if std is None:
        std = stat_values.std()
   
    # Calculate historical frequency
    historical_freq = (stat_values > line_value).mean()
   
    # Calculate probability using normal distribution
    if std > 0:  # Avoid division by zero
        z_score = (line_value - mean) / std
        prob_over = 1 - stats.norm.cdf(z_score)
    else:
        # If std is 0, all values are the same
        prob_over = 1.0 if mean > line_value else 0.0
   
    return prob_over, historical_freq, mean, std

def analyze_playoff_betting_lines(player_name, team_abbr, stats_df, std_df, all_games, betting_lines=None, team_games=None):
    """Analyze betting lines for playoffs with special weight on playoff context."""
    print("\n" + "="*50)
    print(f"PLAYOFF BETTING LINE ANALYSIS FOR {player_name} vs {team_abbr}")
    print("="*50)
   
    all_stats = ['PTS', 'AST', 'TRB', 'PRA']
    
    # If no betting lines provided, prompt for them
    if not betting_lines:
        betting_lines = {}
        print("\nEnter playoff betting lines (leave blank to skip):")
        for stat in all_stats:
            line_input = input(f"{stat} line: ")
            if line_input.strip():
                try:
                    betting_lines[stat] = float(line_input)
                except ValueError:
                    print(f"Invalid input for {stat}. Skipping.")
   
    if not betting_lines:
        print("No betting lines entered. Skipping analysis.")
        return []
   
    # Get last 10 games specifically for analysis
    # Make sure they're valid games with stats
    last_10_games = all_games.head(10)
   
    # Analyze each entered betting line
    results = []
    for stat, line in betting_lines.items():
        print(f"\n{'-'*40}")
        print(f"Playoff Analysis for {player_name} {stat} > {line}")
        print(f"{'-'*40}")
       
        # Get index for this stat
        try:
            stat_idx = stats_df[stats_df['Stat'] == stat].index[0]
           
            # Get means and standard deviations from our pre-calculated DataFrames
            playoff_avg = stats_df.loc[stat_idx, 'Playoff Career Avg']
            last_10_avg = stats_df.loc[stat_idx, 'Last 10 Playoff Games Avg']
            team_avg = stats_df.loc[stat_idx, f'Vs {team_abbr} Playoff Avg']
           
            playoff_std = std_df.loc[stat_idx, 'Playoff Career StdDev']
            last_10_std = std_df.loc[stat_idx, 'Last 10 Playoff Games StdDev']
            team_std = std_df.loc[stat_idx, f'Vs {team_abbr} Playoff StdDev']
           
            # Calculate probabilities based on last 10 playoff games
            if 'PRA' in last_10_games.columns and stat == 'PRA':
                prob_over_10, freq_over_10, _, _ = calculate_betting_probability(
                    last_10_games['PRA'], line, last_10_avg, last_10_std
                )
            elif stat in last_10_games.columns:
                prob_over_10, freq_over_10, _, _ = calculate_betting_probability(
                    last_10_games[stat], line, last_10_avg, last_10_std
                )
            else:
                prob_over_10, freq_over_10 = None, None
           
            # Calculate probabilities based on playoff games against this team
            if team_games is not None and not team_games.empty:
                if 'PRA' in team_games.columns and stat == 'PRA':
                    prob_over_team, freq_over_team, _, _ = calculate_betting_probability(
                        team_games['PRA'], line, team_avg, team_std
                    )
                elif stat in team_games.columns:
                    prob_over_team, freq_over_team, _, _ = calculate_betting_probability(
                        team_games[stat], line, team_avg, team_std
                    )
                else:
                    prob_over_team, freq_over_team = None, None
            else:
                prob_over_team, freq_over_team = None, None
           
            # Calculate career playoff probability
            if 'PRA' in all_games.columns and stat == 'PRA':
                prob_over_career, freq_over_career, _, _ = calculate_betting_probability(
                    all_games['PRA'].dropna(), line, playoff_avg, playoff_
