import pandas as pd
import numpy as np
import re
import requests
from bs4 import BeautifulSoup
from scipy import stats
from io import StringIO

def create_player_playoff_url(first_name, last_name, season=None):
    """
    Create the correct Basketball Reference URL for a player's playoff data.
    Format: first letter of last name/first 5 letters of last name + first 2 letters of first name
    Example: Stephen Curry -> c/curryst01/gamelog-playoffs/
    """
    # Format names correctly
    first_name = first_name.strip().lower()
    last_name = last_name.strip().lower()
   
    # Create the initial part of the player ID
    first_letter = last_name[0]
    last_name_part = last_name[:5]
    first_name_part = first_name[:2]
   
    # Construct base URL pattern
    player_id = f"{last_name_part}{first_name_part}01"
   
    # If season is specified, add it to the URL
    if season:
        base_url = f"https://www.basketball-reference.com/players/{first_letter}/{player_id}/gamelog-playoffs/{season}"
    else:
        base_url = f"https://www.basketball-reference.com/players/{first_letter}/{player_id}/gamelog-playoffs/#player_game_log_post"
   
    # Check if this URL exists
    try:
        response = requests.get(base_url)
        if response.status_code == 200:
            return base_url, player_id
       
        # If not found, we should search more systematically
        print(f"Player page not found. Attempted URL: {base_url}")
        print("The player ID might have a different sequence number or format.")
        return None, None
    except Exception as e:
        print(f"Error accessing URL: {e}")
        return None, None

def get_playoff_games(player_url):
    """Fetches and returns all available playoff games of a player."""
    try:
        # Get the HTML content
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(player_url, headers=headers)
       
        # Check if response is successful
        if response.status_code != 200:
            print(f"Failed to access {player_url}, status code: {response.status_code}")
            return None
           
        soup = BeautifulSoup(response.content, 'html.parser')
       
        # Find all playoff tables
        playoff_tables = []
       
        # Check for tables with different possible ID patterns
        table_patterns = [
            re.compile(r'pgl_basic_playoffs'),  # Standard pattern
            re.compile(r'playoffs_.*'),         # Alternative pattern
            re.compile(r'post_.*')              # Another possible pattern
        ]
       
        for pattern in table_patterns:
            tables = soup.find_all('table', id=pattern)
            if tables:
                playoff_tables.extend(tables)
       
        # If no tables found with IDs, try looking for tables with specific class names
        if not playoff_tables:
            # Look for tables that might contain playoff data
            for table in soup.find_all('table'):
                # Look for headers or captions that indicate playoff data
                caption = table.find('caption')
                if caption and ('playoff' in caption.text.lower() or 'post' in caption.text.lower()):
                    playoff_tables.append(table)
               
                # Check for playoff indicators in table classes or attributes
                if table.has_attr('class') and any('playoff' in c.lower() for c in table['class']):
                    playoff_tables.append(table)
       
        # Last resort: if still no tables found, try to find any div containing playoff data
        if not playoff_tables:
            playoff_divs = soup.find_all('div', id=re.compile(r'div_playoffs'))
            for div in playoff_divs:
                tables = div.find_all('table')
                playoff_tables.extend(tables)
       
        if not playoff_tables:
            print(f"No playoff tables found at {player_url}")
            # Try to determine if this is due to no playoff appearances or website structure issue
            if "Playoffs" not in soup.text and "playoff" not in soup.text.lower():
                print("Player may not have playoff appearances.")
            else:
                print("Tables exist but could not be properly accessed. Website structure may have changed.")
            return None
       
        # Process all tables
        all_playoff_data = []
        for table in playoff_tables:
            # Convert HTML table to DataFrame - use StringIO to avoid FutureWarning
            html = str(table)
            try:
                dfs = pd.read_html(StringIO(html))
                if not dfs:
                    continue
                df = dfs[0].copy()  # Create a copy to avoid SettingWithCopyWarning
               
                # Clean the DataFrame - remove header rows and summary rows
                if 'Rk' in df.columns:
                    # Filter out header repetitions and summary rows (TOT)
                    df = df[~df['Rk'].isin(['Rk', 'TOT'])].copy()
                    # Convert 'Rk' to numeric to further filter out non-numeric values
                    df['Rk'] = pd.to_numeric(df['Rk'], errors='coerce')
                    df = df[df['Rk'].notna()].copy()
               
                # Extract season information
                season = "Unknown"
                if table.get('id'):
                    season_match = re.search(r'playoffs_(\d+)', table.get('id', ''))
                    if season_match:
                        season = season_match.group(1)
                else:
                    # Try to extract season from nearby elements
                    for element in table.previous_siblings:
                        if hasattr(element, 'text') and re.search(r'20\d{2}-\d{2}', element.text):
                            season_match = re.search(r'20\d{2}-\d{2}', element.text)
                            if season_match:
                                season = season_match.group(0)
                                break
               
                # Add series information based on patterns in data (use .loc to avoid SettingWithCopyWarning)
                if 'Opp' in df.columns:
                    df.loc[:, 'Series'] = df['Opp'].apply(lambda x: x if pd.notna(x) else '')
                else:
                    df.loc[:, 'Series'] = ''
                   
                # Add Game_In_Series - check if 'G' or 'Gm' or 'Game' column exists
                game_col = None
                for possible_col in ['Gm', 'G', 'Game', '#']:
                    if possible_col in df.columns:
                        game_col = possible_col
                        break
                       
                if game_col:
                    df.loc[:, 'Game_In_Series'] = df[game_col].apply(
                        lambda x: int(x) if pd.notna(x) and str(x).isdigit() else 0)
                else:
                    df.loc[:, 'Game_In_Series'] = 0
               
                # Ensure we have a 'Gm' column to avoid KeyError later
                if 'Gm' not in df.columns:
                    if game_col:
                        df.loc[:, 'Gm'] = df[game_col]
                    else:
                        df.loc[:, 'Gm'] = df['Game_In_Series']
               
                # Add the season information
                df.loc[:, 'Season'] = season
               
                # Make sure required columns exist
                required_cols = ['PTS', 'AST', 'TRB', 'MP', 'Date', 'Opp', 'Result']
                for col in required_cols:
                    if col not in df.columns:
                        if col == 'PTS' and 'PT' in df.columns:  # Some tables use PT instead of PTS
                            df.loc[:, 'PTS'] = df['PT']
                        elif col == 'TRB' and 'REB' in df.columns:  # Some tables use REB instead of TRB
                            df.loc[:, 'TRB'] = df['REB']
                        else:
                            df.loc[:, col] = np.nan
               
                all_playoff_data.append(df)
               
            except Exception as e:
                print(f"Error processing table: {e}")
                continue
       
        # Combine all tables
        if all_playoff_data:
            combined_df = pd.concat(all_playoff_data, ignore_index=True)
           
            # Additional filtering for summary rows that might have slipped through
            if 'Rk' in combined_df.columns:
                # Convert Rk to numeric and filter out non-numeric values
                combined_df['Rk'] = pd.to_numeric(combined_df['Rk'], errors='coerce')
                combined_df = combined_df[combined_df['Rk'].notna()].copy()
           
            # Filter out rows that might contain "Totals" in any column
            for col in combined_df.columns:
                if combined_df[col].dtype == 'object':
                    combined_df = combined_df[~combined_df[col].astype(str).str.contains('Total', case=False, na=False)].copy()
           
            # Convert date to datetime
            combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')
           
            # Ensure numeric conversion for key stats
            numeric_cols = ['PTS', 'AST', 'TRB', 'MP', 'FG', 'FGA', '3P', '3PA', '2P', '2PA', 'FT', 'FTA',
                           'ORB', 'DRB', 'STL', 'BLK', 'TOV', 'PF', '+/-']
            for col in numeric_cols:
                if col in combined_df.columns:
                    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')
           
            # Add PRA (Points + Rebounds + Assists)
            if all(col in combined_df.columns for col in ['PTS', 'AST', 'TRB']):
                combined_df.loc[:, 'PRA'] = combined_df['PTS'] + combined_df['AST'] + combined_df['TRB']
           
            # Sort by date descending (most recent first)
            combined_df = combined_df.sort_values(by='Date', ascending=False)
           
            return combined_df
        else:
            print(f"No playoff data found for player at {player_url}")
            return None
    except Exception as e:
        print(f"Error fetching playoff data from {player_url}: {e}")
        return None

def extract_series_info(df):
    """Extract playoff series information from the dataframe."""
    if df is None or df.empty:
        return None
   
    # Make a copy to avoid modifying the original
    series_df = df.copy()
   
    # Filter out summary rows which can inflate statistics
    if 'Rk' in series_df.columns:
        # Convert to numeric and filter out non-numeric values (like 'Rk', 'TOT')
        series_df['Rk'] = pd.to_numeric(series_df['Rk'], errors='coerce')
        series_df = series_df[series_df['Rk'].notna()].copy()
   
    # Extract series information - handling potential missing columns
    def create_series_info(row):
        season = row['Season'] if 'Season' in row and pd.notna(row['Season']) else 'Unknown'
        opponent = row['Opp'] if 'Opp' in row and pd.notna(row['Opp']) else 'Unknown'
        game = row['Gm'] if 'Gm' in row and pd.notna(row['Gm']) else (
               row['Game_In_Series'] if 'Game_In_Series' in row and pd.notna(row['Game_In_Series']) else 'Unknown')
       
        return f"{season} - {opponent} - Game {game}"
   
    # Apply the function safely
    series_df.loc[:, 'Series_Info'] = series_df.apply(create_series_info, axis=1)
   
    # Group by opponent and season to identify different series
    def create_series_id(row):
        season = row['Season'] if 'Season' in row and pd.notna(row['Season']) else 'Unknown'
        opponent = row['Opp'] if 'Opp' in row and pd.notna(row['Opp']) else 'Unknown'
        return f"{season}_{opponent}"
   
    series_df.loc[:, 'Series_ID'] = series_df.apply(create_series_id, axis=1)
   
    return series_df

def get_games_vs_team(df, team_abbr):
    """Filter games against a specific team."""
    if df is None or df.empty:
        return None
   
    # Filter games against the team
    team_games = df[df['Opp'].str.contains(team_abbr, na=False)].copy()
   
    return team_games

def calculate_playoff_stats(df, team_abbr=None):
    """Calculate playoff statistics for a player."""
    if df is None or df.empty:
        print("No playoff data available.")
        return None, None, None
   
    # Make a clean copy of the dataframe
    df_clean = df.copy()
   
    # Filter out summary rows to avoid inflating averages
    if 'Rk' in df_clean.columns:
        # Convert Rk to numeric and filter out non-numeric values (like 'Rk', 'TOT')
        df_clean['Rk'] = pd.to_numeric(df_clean['Rk'], errors='coerce')
        df_clean = df_clean[df_clean['Rk'].notna()].copy()
   
    # Additional filtering for 'Total' rows that might inflate stats
    for col in df_clean.columns:
        if df_clean[col].dtype == 'object':
            df_clean = df_clean[~df_clean[col].astype(str).str.contains('Total', case=False, na=False)].copy()
   
    # Add series context information
    series_df = extract_series_info(df_clean)
   
    # Make sure PTS, AST, TRB are numeric
    for col in ['PTS', 'AST', 'TRB']:
        if col in series_df.columns:
            series_df[col] = pd.to_numeric(series_df[col], errors='coerce')
   
    # Calculate overall playoff averages - only include rows with valid points data
    valid_data = series_df[series_df['PTS'].notna()].copy()
   
    playoff_avg = {
        'PTS': valid_data['PTS'].mean() if not valid_data.empty else np.nan,
        'AST': valid_data['AST'].mean() if not valid_data.empty else np.nan,
        'TRB': valid_data['TRB'].mean() if not valid_data.empty else np.nan,
        'PRA': valid_data['PRA'].mean() if 'PRA' in valid_data.columns and not valid_data.empty else np.nan
    }
   
    # Calculate standard deviations
    playoff_std = {
        'PTS': valid_data['PTS'].std() if not valid_data.empty else np.nan,
        'AST': valid_data['AST'].std() if not valid_data.empty else np.nan,
        'TRB': valid_data['TRB'].std() if not valid_data.empty else np.nan,
        'PRA': valid_data['PRA'].std() if 'PRA' in valid_data.columns and not valid_data.empty else np.nan
    }
   
    # Get last 10 playoff games - make sure they're valid games with stats
    last_10_games = valid_data.head(10)
   
    # Calculate last 10 games averages
    last_10_avg = {
        'PTS': last_10_games['PTS'].mean() if not last_10_games.empty else np.nan,
        'AST': last_10_games['AST'].mean() if not last_10_games.empty else np.nan,
        'TRB': last_10_games['TRB'].mean() if not last_10_games.empty else np.nan,
        'PRA': last_10_games['PRA'].mean() if 'PRA' in last_10_games.columns and not last_10_games.empty else np.nan
    }
   
    # Last 10 games standard deviation
    last_10_std = {
        'PTS': last_10_games['PTS'].std() if not last_10_games.empty else np.nan,
        'AST': last_10_games['AST'].std() if not last_10_games.empty else np.nan,
        'TRB': last_10_games['TRB'].std() if not last_10_games.empty else np.nan,
        'PRA': last_10_games['PRA'].std() if 'PRA' in last_10_games.columns and not last_10_games.empty else np.nan
    }
   
    # If team is specified, calculate stats against that team
    if team_abbr:
        team_games = get_games_vs_team(valid_data, team_abbr)
       
        if team_games is not None and not team_games.empty:
            team_avg = {
                'PTS': team_games['PTS'].mean(),
                'AST': team_games['AST'].mean(),
                'TRB': team_games['TRB'].mean(),
                'PRA': team_games['PRA'].mean() if 'PRA' in team_games.columns else np.nan
            }
           
            team_std = {
                'PTS': team_games['PTS'].std(),
                'AST': team_games['AST'].std(),
                'TRB': team_games['TRB'].std(),
                'PRA': team_games['PRA'].std() if 'PRA' in team_games.columns else np.nan
            }
        else:
            team_avg = {stat: float('nan') for stat in ['PTS', 'AST', 'TRB', 'PRA']}
            team_std = {stat: float('nan') for stat in ['PTS', 'AST', 'TRB', 'PRA']}
    else:
        team_avg = {stat: float('nan') for stat in ['PTS', 'AST', 'TRB', 'PRA']}
        team_std = {stat: float('nan') for stat in ['PTS', 'AST', 'TRB', 'PRA']}
   
    # Create DataFrames for summary display
    stats_df = pd.DataFrame({
        'Stat': ['PTS', 'AST', 'TRB', 'PRA'],
        'Playoff Career Avg': [playoff_avg['PTS'], playoff_avg['AST'], playoff_avg['TRB'], playoff_avg['PRA']],
        'Last 10 Playoff Games Avg': [last_10_avg['PTS'], last_10_avg['AST'], last_10_avg['TRB'], last_10_avg['PRA']],
        f'Vs {team_abbr} Playoff Avg': [team_avg['PTS'], team_avg['AST'], team_avg['TRB'], team_avg['PRA']]
    })
   
    std_df = pd.DataFrame({
        'Stat': ['PTS', 'AST', 'TRB', 'PRA'],
        'Playoff Career StdDev': [playoff_std['PTS'], playoff_std['AST'], playoff_std['TRB'], playoff_std['PRA']],
        'Last 10 Playoff Games StdDev': [last_10_std['PTS'], last_10_std['AST'], last_10_std['TRB'], last_10_std['PRA']],
        f'Vs {team_abbr} Playoff StdDev': [team_std['PTS'], team_std['AST'], team_std['TRB'], team_std['PRA']]
    })
   
    # Round for cleaner display
    for col in stats_df.columns[1:]:
        stats_df[col] = stats_df[col].round(1)
    for col in std_df.columns[1:]:
        std_df[col] = std_df[col].round(1)
   
    return stats_df, std_df, valid_data

def calculate_betting_probability(stat_values, line_value, mean=None, std=None):
    """
    Calculate the probability of a player exceeding a betting line.
    Uses a combination of normal distribution and historical frequency.
    """
    # Remove NaN values
    stat_values = stat_values.dropna()
    if len(stat_values) < 3:
        return None, None, None, None
   
    # Calculate mean and standard deviation if not provided
    if mean is None:
        mean = stat_values.mean()
    if std is None:
        std = stat_values.std()
   
    # Calculate historical frequency
    historical_freq = (stat_values > line_value).mean()
   
    # Calculate probability using normal distribution
    if std > 0:  # Avoid division by zero
        z_score = (line_value - mean) / std
        prob_over = 1 - stats.norm.cdf(z_score)
    else:
        # If std is 0, all values are the same
        prob_over = 1.0 if mean > line_value else 0.0
   
    return prob_over, historical_freq, mean, std

def analyze_playoff_betting_lines(player_name, team_abbr, stats_df, std_df, all_games, team_games=None):
    """Analyze betting lines for playoffs with special weight on playoff context."""
    print("\n" + "="*50)
    print(f"PLAYOFF BETTING LINE ANALYSIS FOR {player_name} vs {team_abbr}")
    print("="*50)
   
    all_stats = ['PTS', 'AST', 'TRB', 'PRA']
    betting_lines = {}
   
    # Prompt for betting lines
    print("\nEnter playoff betting lines (leave blank to skip):")
    for stat in all_stats:
        line_input = input(f"{stat} line: ")
        if line_input.strip():
            try:
                betting_lines[stat] = float(line_input)
            except ValueError:
                print(f"Invalid input for {stat}. Skipping.")
   
    if not betting_lines:
        print("No betting lines entered. Skipping analysis.")
        return
   
    # Get last 10 games specifically for analysis
    # Make sure they're valid games with stats
    last_10_games = all_games.head(10)
   
    # Analyze each entered betting line
    results = []
    for stat, line in betting_lines.items():
        print(f"\n{'-'*40}")
        print(f"Playoff Analysis for {player_name} {stat} > {line}")
        print(f"{'-'*40}")
       
        # Get index for this stat
        try:
            stat_idx = stats_df[stats_df['Stat'] == stat].index[0]
           
            # Get means and standard deviations from our pre-calculated DataFrames
            playoff_avg = stats_df.loc[stat_idx, 'Playoff Career Avg']
            last_10_avg = stats_df.loc[stat_idx, 'Last 10 Playoff Games Avg']
            team_avg = stats_df.loc[stat_idx, f'Vs {team_abbr} Playoff Avg']
           
            playoff_std = std_df.loc[stat_idx, 'Playoff Career StdDev']
            last_10_std = std_df.loc[stat_idx, 'Last 10 Playoff Games StdDev']
            team_std = std_df.loc[stat_idx, f'Vs {team_abbr} Playoff StdDev']
           
            # Calculate probabilities based on last 10 playoff games
            if 'PRA' in last_10_games.columns and stat == 'PRA':
                prob_over_10, freq_over_10, _, _ = calculate_betting_probability(
                    last_10_games['PRA'], line, last_10_avg, last_10_std
                )
            elif stat in last_10_games.columns:
                prob_over_10, freq_over_10, _, _ = calculate_betting_probability(
                    last_10_games[stat], line, last_10_avg, last_10_std
                )
            else:
                prob_over_10, freq_over_10 = None, None
           
            # Calculate probabilities based on playoff games against this team
            if team_games is not None and not team_games.empty:
                if 'PRA' in team_games.columns and stat == 'PRA':
                    prob_over_team, freq_over_team, _, _ = calculate_betting_probability(
                        team_games['PRA'], line, team_avg, team_std
                    )
                elif stat in team_games.columns:
                    prob_over_team, freq_over_team, _, _ = calculate_betting_probability(
                        team_games[stat], line, team_avg, team_std
                    )
                else:
                    prob_over_team, freq_over_team = None, None
            else:
                prob_over_team, freq_over_team = None, None
           
            # Calculate career playoff probability
            if 'PRA' in all_games.columns and stat == 'PRA':
                prob_over_career, freq_over_career, _, _ = calculate_betting_probability(
                    all_games['PRA'].dropna(), line, playoff_avg, playoff_std
                )
            elif stat in all_games.columns:
                prob_over_career, freq_over_career, _, _ = calculate_betting_probability(
                    all_games[stat].dropna(), line, playoff_avg, playoff_std
                )
            else:
                prob_over_career, freq_over_career = None, None
           
            # Weighted average probability - playoff specific weighting
            # 50% weight to recent playoff form, 30% to team-specific playoff stats, 20% to career playoff stats
            weights_sum = 0
            weighted_prob = 0
           
            if prob_over_10 is not None:
                weighted_prob += 0.5 * prob_over_10
                weights_sum += 0.5
           
            if prob_over_team is not None:
                weighted_prob += 0.3 * prob_over_team
                weights_sum += 0.3
           
            if prob_over_career is not None:
                weighted_prob += 0.2 * prob_over_career
                weights_sum += 0.2
           
            if weights_sum > 0:
                final_prob = weighted_prob / weights_sum
            else:
                final_prob = None
           
            # Print results
            print(f"Playoff Career Average: {playoff_avg:.1f}")
            print(f"Last 10 Playoff Games Average: {last_10_avg:.1f}")
            if not np.isnan(team_avg):
                print(f"Playoff Average vs {team_abbr}: {team_avg:.1f}")
           
            if prob_over_10 is not None and freq_over_10 is not None:
                print(f"\nLast 10 Playoff Games:")
                print(f"- Exceeded {line} in {int(freq_over_10*100)}% of games")
                print(f"- Statistical probability of exceeding {line}: {prob_over_10*100:.1f}%")
           
            if prob_over_team is not None and freq_over_team is not None and not np.isnan(team_avg):
                print(f"\nPlayoff Games vs {team_abbr}:")
                print(f"- Exceeded {line} in {int(freq_over_team*100)}% of games")
                print(f"- Statistical probability of exceeding {line}: {prob_over_team*100:.1f}%")
           
            if final_prob is not None:
                print(f"\nFINAL PLAYOFF RECOMMENDATION:")
                if final_prob > 0.65:
                    recommendation = f"STRONG OVER ({final_prob*100:.1f}%)"
                elif final_prob > 0.55:
                    recommendation = f"LEAN OVER ({final_prob*100:.1f}%)"
                elif final_prob < 0.35:
                    recommendation = f"STRONG UNDER ({(1-final_prob)*100:.1f}%)"
                elif final_prob < 0.45:
                    recommendation = f"LEAN UNDER ({(1-final_prob)*100:.1f}%)"
                else:
                    recommendation = f"COIN FLIP ({final_prob*100:.1f}%)"
                print(f"{stat} > {line}: {recommendation}")
               
                # Store results for summary
                results.append({
                    'Stat': stat,
                    'Line': line,
                    'Probability': final_prob,
                    'Recommendation': recommendation
                })
            else:
                print("Insufficient data for recommendation")
       
        except (IndexError, KeyError) as e:
            print(f"Error analyzing {stat}: {e}")
            continue
   
    # Print summary
    if results:
        print("\n" + "="*50)
        print("SUMMARY OF PLAYOFF RECOMMENDATIONS")
        print("="*50)
        for result in results:
            print(f"{result['Stat']} > {result['Line']}: {result['Recommendation']}")

def analyze_series_context(series_df, team_abbr=None):
    """Analyze performance based on series context (game number, home/away, etc.)"""
    if series_df is None or series_df.empty:
        print("No playoff data available for series context analysis.")
        return
   
    print("\n" + "="*50)
    print("PLAYOFF SERIES CONTEXT ANALYSIS")
    print("="*50)
   
    # Make a clean copy to avoid pandas warnings
    df = series_df.copy()
   
    # Filter by team if specified
    if team_abbr:
        team_df = df[df['Opp'].str.contains(team_abbr, na=False)].copy()
        if team_df.empty:
            print(f"No playoff games found against {team_abbr}")
            team_df = df  # Use all data if no games against specified team
        else:
            df = team_df
   
    # Add home/away indicator
    if '@' in df.columns:
        df.loc[:, 'Home'] = ~df['@'].notna()
    else:
        # Try to determine home/away from other columns
        if 'Location' in df.columns:
            # Some data may have a Location column instead
            df.loc[:, 'Home'] = df['Location'].apply(lambda x: 'H' in str(x).upper() if pd.notna(x) else False)
        elif 'Venue' in df.columns:
            # Or a Venue column
            df.loc[:, 'Home'] = df['Venue'].apply(lambda x: 'H' in str(x).upper() if pd.notna(x) else False)
        else:
            print("Could not determine home/away status for games. Assuming neutral venue.")
            df.loc[:, 'Home'] = False
   
    # Game number analysis
    print("\nPerformance by Game Number in Series:")
    if 'Gm' in df.columns and not df['Gm'].isna().all():
        game_num_col = 'Gm'
    elif 'Game_In_Series' in df.columns and not df['Game_In_Series'].isna().all():
        game_num_col = 'Game_In_Series'
    else:
        game_num_col = None
        print("Game number information not available in data.")
   
    if game_num_col:
        # Convert to numeric and handle non-numeric values
        df.loc[:, game_num_col] = pd.to_numeric(df[game_num_col], errors='coerce')
       
        # Group by game number if we have valid data
        valid_games = df[df[game_num_col].notna()].copy()
        if not valid_games.empty and 'PTS' in valid_games.columns:
            try:
                game_num_stats = valid_games.groupby(game_num_col)['PTS'].agg(['mean', 'std', 'count']).reset_index()
                game_num_stats.columns = ['Game Number', 'Avg PTS', 'StdDev', 'Games']
                game_num_stats = game_num_stats.sort_values('Game Number')
                print(game_num_stats.round(1))
            except Exception as e:
                print(f"Error calculating game number statistics: {e}")
        else:
            print("No valid game number data available.")
   
    # Home vs Away analysis
    print("\nHome vs Away Performance:")
    try:
        required_cols = ['PTS', 'AST', 'TRB']
        available_cols = [col for col in required_cols if col in df.columns]
       
        if available_cols and not df['Home'].isna().all():
            home_away_stats = df.groupby('Home')[available_cols].agg(['mean', 'std', 'count']).reset_index()
            home_away_stats.loc[:, 'Location'] = home_away_stats['Home'].map({True: 'Home', False: 'Away'})
           
            # Properly drop 'Home' from MultiIndex
            home_away_stats = home_away_stats.drop(('Home', ''), axis=1)
           
            # Reorganize for better display
            stats_display = pd.DataFrame({'Location': home_away_stats['Location']})
           
            for col in available_cols:
                try:
                    stats_display[f'{col} Avg'] = home_away_stats[(col, 'mean')].round(1)
                except:
                    flat_cols = [f"{a}_{b}" for a, b in home_away_stats.columns if isinstance(a, str) and isinstance(b, str)]
                    if f"{col}_mean" in flat_cols:
                        col_idx = flat_cols.index(f"{col}_mean")
                        stats_display[f'{col} Avg'] = home_away_stats.iloc[:, col_idx].round(1)
           
            if 'PTS' in available_cols:
                try:
                    stats_display['Games'] = home_away_stats[('PTS', 'count')]
                except:
                    flat_cols = [f"{a}_{b}" for a, b in home_away_stats.columns if isinstance(a, str) and isinstance(b, str)]
                    if "PTS_count" in flat_cols:
                        col_idx = flat_cols.index("PTS_count")
                        stats_display['Games'] = home_away_stats.iloc[:, col_idx]
           
            print(stats_display)
        else:
            print("Required data for home/away analysis not available.")
    except Exception as e:
        print(f"Error in home/away analysis: {e}")
   
    # Win vs Loss analysis
    print("\nPerformance in Wins vs Losses:")
    if 'Result' in df.columns:
        try:
            # Extract win/loss from result column - use .loc to avoid SettingWithCopyWarning
            df.loc[:, 'Win'] = df['Result'].apply(lambda x: str(x).startswith('W') if pd.notna(x) else None)
           
            # Check if we have valid win/loss data
            valid_results = df[df['Win'].notna()].copy()
           
            if not valid_results.empty:
                required_cols = ['PTS', 'AST', 'TRB']
                available_cols = [col for col in required_cols if col in valid_results.columns]
               
                if available_cols:
                    win_loss_stats = valid_results.groupby('Win')[available_cols].agg(['mean', 'std', 'count']).reset_index()
                    win_loss_stats.loc[:, 'Outcome'] = win_loss_stats['Win'].map({True: 'Wins', False: 'Losses'})
                   
                    # Properly drop from MultiIndex
                    win_loss_stats = win_loss_stats.drop(('Win', ''), axis=1)
                   
                    # Reorganize for better display
                    outcome_display = pd.DataFrame({'Outcome': win_loss_stats['Outcome']})
                   
                    for col in available_cols:
                        try:
                            outcome_display[f'{col} Avg'] = win_loss_stats[(col, 'mean')].round(1)
                        except:
                            flat_cols = [f"{a}_{b}" for a, b in win_loss_stats.columns if isinstance(a, str) and isinstance(b, str)]
                            if f"{col}_mean" in flat_cols:
                                col_idx = flat_cols.index(f"{col}_mean")
                                outcome_display[f'{col} Avg'] = win_loss_stats.iloc[:, col_idx].round(1)
                   
                    if 'PTS' in available_cols:
                        try:
                            outcome_display['Games'] = win_loss_stats[('PTS', 'count')]
                        except:
                            flat_cols = [f"{a}_{b}" for a, b in win_loss_stats.columns if isinstance(a, str) and isinstance(b, str)]
                            if "PTS_count" in flat_cols:
                                col_idx = flat_cols.index("PTS_count")
                                outcome_display['Games'] = win_loss_stats.iloc[:, col_idx]
                   
                    print(outcome_display)
                else:
                    print("Required statistics not available for win/loss analysis.")
            else:
                print("No valid win/loss data available.")
        except Exception as e:
            print(f"Error in win/loss analysis: {e}")
    else:
        print("Result information not available for win/loss analysis.")

def get_team_abbreviation_map():
    """Returns a dictionary mapping team names to their abbreviations."""
    return {
        "atlanta": "ATL", "hawks": "ATL",
        "boston": "BOS", "celtics": "BOS",
        "brooklyn": "BRK", "nets": "BRK",
        "charlotte": "CHO", "hornets": "CHO",
        "chicago": "CHI", "bulls": "CHI",
        "cleveland": "CLE", "cavaliers": "CLE", "cavs": "CLE",
        "dallas": "DAL", "mavericks": "DAL", "mavs": "DAL",
        "denver": "DEN", "nuggets": "DEN",
        "detroit": "DET", "pistons": "DET",
        "golden state": "GSW", "warriors": "GSW",
        "houston": "HOU", "rockets": "HOU",
        "indiana": "IND", "pacers": "IND",
        "la clippers": "LAC", "los angeles clippers": "LAC", "clippers": "LAC",
        "la lakers": "LAL", "los angeles lakers": "LAL", "lakers": "LAL",
        "memphis": "MEM", "grizzlies": "MEM",
        "miami": "MIA", "heat": "MIA",
        "milwaukee": "MIL", "bucks": "MIL",
        "minnesota": "MIN", "timberwolves": "MIN", "wolves": "MIN",
        "new orleans": "NOP", "pelicans": "NOP", "pels": "NOP",
        "new york": "NYK", "knicks": "NYK",
        "oklahoma city": "OKC", "thunder": "OKC",
        "orlando": "ORL", "magic": "ORL",
        "philadelphia": "PHI", "76ers": "PHI", "sixers": "PHI",
        "phoenix": "PHO", "suns": "PHO",
        "portland": "POR", "trail blazers": "POR", "blazers": "POR",
        "sacramento": "SAC", "kings": "SAC",
        "san antonio": "SAS", "spurs": "SAS",
        "toronto": "TOR", "raptors": "TOR",
        "utah": "UTA", "jazz": "UTA",
        "washington": "WAS", "wizards": "WAS"
    }

def main():
    # Get player name from user
    print("NBA PLAYOFF BETTING ANALYZER")
    print("============================")
    print("Enter player information:")
    first_name = input("First name: ")
    last_name = input("Last name: ")
   
    # Create player URL for playoff data
    player_url, player_id = create_player_playoff_url(first_name, last_name)
    if not player_url:
        return
   
    # Get all playoff games
    print(f"\nFetching playoff data for {first_name} {last_name}...")
    all_playoff_games = get_playoff_games(player_url)
   
    if all_playoff_games is None or all_playoff_games.empty:
        print(f"No playoff data found for {first_name} {last_name}")
        return
   
    print(f"Found {len(all_playoff_games)} playoff games for {first_name} {last_name}")
   
    # Get team input from user
    print("\nEnter opponent team information (e.g., 'Lakers', 'GSW', 'Boston'):")
    team_input = input("Team: ").lower()
   
    # Map team input to abbreviation
    team_map = get_team_abbreviation_map()
    team_abbr = None
   
    # Check if direct input matches an abbreviation
    team_abbr_upper = team_input.upper()
    if team_abbr_upper in [abbr for abbr in team_map.values()]:
        team_abbr = team_abbr_upper
    else:
        # Look up the abbreviation from the team name
        for name, abbr in team_map.items():
            if team_input in name:
                team_abbr = abbr
                break
   
    if not team_abbr:
        print(f"Could not find team abbreviation for '{team_input}'")
        print("Using common abbreviations like 'LAL' for Lakers, 'GSW' for Warriors, etc.")
        team_abbr = input("Please enter the correct team abbreviation: ").upper()
   
    # Calculate playoff statistics
    print(f"\nAnalyzing playoff stats for {first_name} {last_name} against {team_abbr}...")
    stats_df, std_df, series_df = calculate_playoff_stats(all_playoff_games, team_abbr)
   
    # Get games against the specific team
    team_games = get_games_vs_team(series_df, team_abbr)
   
    if team_games is not None and not team_games.empty:
        print(f"\nFound {len(team_games)} playoff games against {team_abbr}")
    else:
        print(f"\nNo playoff games found against {team_abbr}")
   
    # Display the statistics
    print("\nPlayoff Statistics Summary:")
    print(stats_df)
    print("\nStandard Deviations:")
    print(std_df)
   
    # Analyze series context
    analyze_series_context(series_df, team_abbr)
   
    # Betting line analysis for playoffs
    analyze_playoff_betting_lines(f"{first_name} {last_name}", team_abbr, stats_df, std_df, series_df, team_games)

if __name__ == "__main__":
    main()
